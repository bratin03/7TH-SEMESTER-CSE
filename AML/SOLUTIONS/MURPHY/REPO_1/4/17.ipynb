{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.17\n",
    "\n",
    "LDA/QDA on height/weight data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import det\n",
    "from numpy.linalg import inv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Load data and parse it into the design matrix X and the target values y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_table(\n",
    "    '../../pmtk3/data/heightWeight/heightWeightData.txt', #Change this to the path to your heightWeightData.txt\n",
    "    header=None, \n",
    "    delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex  Height  Weight\n",
       "0    1      67     125\n",
       "1    2      68     140\n",
       "2    2      67     142\n",
       "3    2      60     110\n",
       "4    2      64      97"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Sex', 'Height', 'Weight']\n",
    "df.columns = columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = df.values\n",
    "X = dataset[:, 1:3]\n",
    "y = dataset[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarks\n",
    "I think Height and Weight are inverted, but I will follow the labels of heightWeightDataRaw.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers\n",
    "\n",
    "The fitting of the model will be performed using MLE, according with section 4.2.4\n",
    "We will build classes for each classifier with the method fit, inspired in scikit-learn interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QDA:\n",
    "        \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.mu = []\n",
    "        self.Sigma = []\n",
    "        self.prior = []\n",
    "        self.classes = []\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        '''Find mu, Sigma and the prior based on the MLE'''\n",
    "        \n",
    "        num_instances = X.shape[0]\n",
    "        num_features = X.shape[1]        \n",
    "        classes = set(y)\n",
    "        \n",
    "        for idx, class_ in enumerate(classes):            \n",
    "            \n",
    "            targets_idx = (y == class_)\n",
    "            nc = len(y[targets_idx])                        \n",
    "            prior = nc/num_instances\n",
    "            \n",
    "            mu = np.sum(X[targets_idx], axis=0)\n",
    "            mu = mu/nc\n",
    "            \n",
    "            Sigma = np.zeros((num_features, num_features))\n",
    "            X_centered = X - mu\n",
    "            X_centered = X_centered[targets_idx]\n",
    "            for idx in range(nc):\n",
    "                Sigma += np.outer(X_centered[idx], X_centered[idx])\n",
    "            Sigma = Sigma/nc                                \n",
    "            \n",
    "            self.prior.append(prior)\n",
    "            self.mu.append(mu)\n",
    "            self.Sigma.append(Sigma)\n",
    "            self.classes.append(class_)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        '''Calculate the accuracy of the model on the dataset'''\n",
    "        \n",
    "        num_instances = X.shape[0]\n",
    "        predictions, _ = self.predict(X)\n",
    "        acc = (y == predictions).sum()\n",
    "        acc /= num_instances\n",
    "        return acc\n",
    "        \n",
    "    \n",
    "    def evaluate(self, x):\n",
    "        '''Evaluate probability of each class'''\n",
    "        \n",
    "        evaluations = []\n",
    "        normalization = 0\n",
    "        for class_idx, class_ in enumerate(self.classes):                        \n",
    "            mu = self.mu[class_idx]\n",
    "            Sigma = self.Sigma[class_idx]\n",
    "            prior = self.prior[class_idx]            \n",
    "            quadratic = -0.5*np.dot((x - mu).T, inv(Sigma))\n",
    "            quadratic = np.dot(quadratic, (x-mu))\n",
    "            p = prior\n",
    "            p *= det(2*pi*Sigma)**(-0.5)\n",
    "            p *= np.exp(quadratic)\n",
    "            normalization += p\n",
    "            evaluations.append([class_, p])\n",
    "        evaluations = ((x[0], x[1]/normalization) for x in evaluations)\n",
    "        return evaluations    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict classes of instances X\"\"\"\n",
    "            \n",
    "        num_instances = X.shape[0]\n",
    "        predictions = []\n",
    "        probabilites = []\n",
    "        for idx in range(num_instances):\n",
    "            evaluation = self.evaluate(X[idx])\n",
    "            prediction, prob = max(evaluation,key=lambda x:x[1]) # MAP decision criteria\n",
    "            predictions.append(prediction)\n",
    "            probabilites.append(prob)\n",
    "        return predictions, probabilites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### LDA\n",
    "\n",
    "The shared covariance matrix is calculated by summing all the outer product terms, with the right mean vector, and divide the final matrix by the total amount of instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LDA:\n",
    "        \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.mu = []\n",
    "        self.Sigma = None\n",
    "        self.prior = []\n",
    "        self.classes = []\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        '''Find mu, Sigma and the prior based on the MLE'''\n",
    "        \n",
    "        num_instances = X.shape[0]\n",
    "        num_features = X.shape[1]                \n",
    "        classes = set(y)\n",
    "        self.Sigma = np.zeros((num_features, num_features))\n",
    "                \n",
    "        for idx, class_ in enumerate(classes):            \n",
    "            \n",
    "            targets_idx = (y == class_)\n",
    "            nc = len(y[targets_idx])                    \n",
    "            prior = nc/num_instances\n",
    "            \n",
    "            mu = np.sum(X[targets_idx], axis=0)\n",
    "            mu = mu/nc\n",
    "            \n",
    "            Sigma = np.zeros((num_features, num_features))\n",
    "            X_centered = X - mu\n",
    "            X_centered = X_centered[targets_idx]\n",
    "            for idx in range(nc):\n",
    "                Sigma += np.outer(X_centered[idx], X_centered[idx])                                            \n",
    "            self.prior.append(prior)\n",
    "            self.mu.append(mu)                        \n",
    "            self.Sigma += Sigma \n",
    "            self.classes.append(class_)\n",
    "        self.Sigma = self.Sigma/num_instances\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        '''Calculate the accuracy of the model on the dataset'''\n",
    "        \n",
    "        num_instances = X.shape[0]\n",
    "        predictions, _ = self.predict(X)\n",
    "        acc = (y == predictions).sum()\n",
    "        acc /= num_instances\n",
    "        return acc\n",
    "        \n",
    "    \n",
    "    def evaluate(self, x):\n",
    "        '''Determine instance class'''\n",
    "        \n",
    "        evaluations = []\n",
    "        normalization = 0\n",
    "        for class_idx, class_ in enumerate(self.classes):                        \n",
    "            mu = self.mu[class_idx]\n",
    "            Sigma = self.Sigma\n",
    "            prior = self.prior[class_idx]            \n",
    "            gamma = -0.5*np.dot(mu.T, inv(Sigma))\n",
    "            gamma = np.dot(gamma, mu)\n",
    "            gamma += np.log(pi)\n",
    "            beta = np.dot(inv(Sigma),mu)\n",
    "            p = np.exp(np.dot(beta.T, x) + gamma)\n",
    "            normalization += p                \n",
    "            evaluations.append([class_, p])        \n",
    "        evaluations = ((x[0], x[1]/normalization) for x in evaluations)\n",
    "        return evaluations    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict classes of instances X\"\"\"\n",
    "            \n",
    "        num_instances = X.shape[0]\n",
    "        predictions = []\n",
    "        probabilites = []\n",
    "\n",
    "        for idx in range(num_instances):\n",
    "            evaluation = self.evaluate(X[idx])\n",
    "            prediction, prob = max(evaluation,key=lambda x:x[1])\n",
    "            predictions.append(prediction)\n",
    "            probabilites.append(prob)\n",
    "        return predictions, probabilites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA misclassification rate on training set: 0.119\n"
     ]
    }
   ],
   "source": [
    "qda = QDA()\n",
    "qda.fit(X, y)\n",
    "score = qda.score(X, y)\n",
    "misclassification = 1 - score\n",
    "print('QDA misclassification rate on training set: {0:.3f}'.format(misclassification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA .isclassification rate on training set: 0.124\n"
     ]
    }
   ],
   "source": [
    "lda = LDA()\n",
    "lda.fit(X, y)\n",
    "score = lda.score(X, y)\n",
    "misclassification = 1 - score\n",
    "print('LDA .isclassification rate on training set: {0:.3f}'.format(misclassification))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as sk_LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as sk_QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA misclassification rate on training set: 0.119\n"
     ]
    }
   ],
   "source": [
    "sk_qda = sk_QDA(priors=qda.prior)\n",
    "sk_qda.fit(X, y)\n",
    "score = sk_qda.score(X,y)\n",
    "misclassification = 1 - score\n",
    "print('QDA misclassification rate on training set: {0:.3f}'.format(misclassification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA .isclassification rate on training set: 0.119\n"
     ]
    }
   ],
   "source": [
    "sk_lda = sk_LDA(priors=lda.prior)\n",
    "sk_lda.fit(X, y)\n",
    "score = sk_lda.score(X,y)\n",
    "misclassification = 1 - score\n",
    "print('LDA .isclassification rate on training set: {0:.3f}'.format(misclassification))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "The results show a reasonable result, where all the misclassifications rates were lower than 13 %. In my implementation, the LDA result was a little bit worse than the QDA (about 0.5 %). Making a sanity check with the scikit-learn implementation we observe an equal score for the QDA and a better score for the scikit LDA. The most likely cause is that they must calculate the shared covariance matrix in a different way (probably in a better way because scikit-learn is a pro machine learning library)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
